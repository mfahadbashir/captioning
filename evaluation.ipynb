{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage.transform\n",
    "import argparse\n",
    "from scipy.misc import imread, imresize\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "from PIL import Image \n",
    "\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(annon_file,min_threshold,load=True):\n",
    "    if (load):\n",
    "        with open('./word2idx', 'rb') as f:\n",
    "            word2idx=pickle.load(f)\n",
    "        with open('./idx2word', 'rb') as f:\n",
    "            idx2word=pickle.load(f)\n",
    "                \n",
    "    else:\n",
    "        word2idx={}\n",
    "        idx2word={}\n",
    "        idx=0\n",
    "\n",
    "        # Adding Start,End and Unkown Token\n",
    "        word='<start>'\n",
    "        word2idx[word]=idx\n",
    "        idx2word[idx]=word\n",
    "        idx+=1\n",
    "\n",
    "        word='<end>'\n",
    "        word2idx[word]=idx\n",
    "        idx2word[idx]=word\n",
    "        idx+=1\n",
    "\n",
    "        word='<unknown>'\n",
    "        word2idx[word]=idx\n",
    "        idx2word[idx]=word\n",
    "        idx+=1\n",
    "        \n",
    "        word='<pad>'\n",
    "        word2idx[word]=idx\n",
    "        idx2word[idx]=word\n",
    "        idx+=1\n",
    "\n",
    "\n",
    "\n",
    "        coco=COCO(annon_file)\n",
    "        keys=coco.anns.keys()\n",
    "        counter=Counter()\n",
    "        for i,key in enumerate(keys):\n",
    "            caption=coco.anns[key]['caption']\n",
    "            tokens=nltk.tokenize.word_tokenize(caption.lower())\n",
    "            counter.update(tokens)\n",
    "\n",
    "        words = [word for word, count in counter.items() if count >= min_threshold]\n",
    "        for word in words:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word]=idx\n",
    "                idx2word[idx]=word\n",
    "                idx+=1\n",
    "        \n",
    "        with open('./word2idx', 'wb') as f:\n",
    "            pickle.dump(word2idx, f)\n",
    "\n",
    "        with open('./idx2word', 'wb') as f:\n",
    "            pickle.dump(idx2word, f)\n",
    "\n",
    "    return word2idx,idx2word\n",
    "\n",
    "\n",
    "anon_file_train='/home/valkyrie/data/2014/annotations/captions_train2014.json'\n",
    "anon_file_val='/home/valkyrie/data/2014/annotations/captions_val2014.json'\n",
    "word2idx,idx2word=build_vocab(anon_file_train,5,load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,base_model,fine_tune=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.base_model = base_model\n",
    "\n",
    "        if (fine_tune==False):\n",
    "            for param in self.base_model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((14,14))\n",
    "        \n",
    "    def forward(self,images):\n",
    "        feat = self.base_model.extract_features(images)  \n",
    "        out = self.adaptive_pool(feat)  \n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim):\n",
    "\n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_att = nn.Linear(encoder_dim, attention_dim)  \n",
    "        self.decoder_att = nn.Linear(decoder_dim, attention_dim)  \n",
    "        self.full_att = nn.Linear(attention_dim, 1)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1) \n",
    "\n",
    "    def forward(self, encoder_out, decoder_hidden):\n",
    "        \n",
    "        att1 = self.encoder_att(encoder_out)  # (batch_size, num_pixels, attention_dim)\n",
    "        att2 = self.decoder_att(decoder_hidden)  # (batch_size, attention_dim)\n",
    "        att = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(2)\n",
    "        alpha = self.softmax(att)  \n",
    "        attention_weighted_encoding = (encoder_out * alpha.unsqueeze(2)).sum(dim=1) \n",
    "\n",
    "        return attention_weighted_encoding, alpha\n",
    "\n",
    "\n",
    "class DecoderWithAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder which uses Attention Network\n",
    "    \"\"\"\n",
    "    def __init__(self, attention_dim, embed_dim, decoder_dim, vocab_size, encoder_dim=1536, dropout=0.5):\n",
    "        \n",
    "        super(DecoderWithAttention, self).__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = dropout\n",
    "        self.attention = Attention(encoder_dim, decoder_dim, attention_dim)  # attention network\n",
    "\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)  # embedding layer\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.decode_step = nn.LSTMCell(embed_dim + encoder_dim, decoder_dim, bias=True)  # decoding LSTMCell\n",
    "        self.init_h = nn.Linear(encoder_dim, decoder_dim)  \n",
    "        self.init_c = nn.Linear(encoder_dim, decoder_dim)  \n",
    "        self.f_beta = nn.Linear(decoder_dim, encoder_dim)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Output Layer\n",
    "        self.fc = nn.Linear(decoder_dim, vocab_size)  \n",
    "        self.init_weights()  \n",
    "\n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)    \n",
    "\n",
    "    def init_hidden_state(self, encoder_out):\n",
    "        mean_encoder_out = encoder_out.mean(dim=1)\n",
    "        h = self.init_h(mean_encoder_out) \n",
    "        c = self.init_c(mean_encoder_out)\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, encoder_out, encoded_captions, caption_lengths):\n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size = self.vocab_size\n",
    "\n",
    "        # Flatten image\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)  \n",
    "        num_pixels = encoder_out.size(1)\n",
    "\n",
    "        caption_lengths, sort_ind = caption_lengths.sort(dim=0, descending=True)\n",
    "        encoder_out = encoder_out[sort_ind]\n",
    "        encoded_captions = encoded_captions[sort_ind]\n",
    "\n",
    "        # Embeddings\n",
    "        embeddings = self.embedding(encoded_captions) \n",
    "\n",
    "        # Initial Cell and Hidden state\n",
    "        h, c = self.init_hidden_state(encoder_out)  \n",
    "\n",
    "        decode_lengths = (caption_lengths - 1).tolist()\n",
    "        \n",
    "        \n",
    "        # Output Tensors\n",
    "        predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(device)\n",
    "        alphas = torch.zeros(batch_size, max(decode_lengths), num_pixels).to(device)\n",
    "\n",
    "        \"\"\"\n",
    "        Main Decode Step. Output used from the previous timestep and the attention weighted encoding is used.\n",
    "        \"\"\"\n",
    "        for size in range(max(decode_lengths)):\n",
    "            batch_size_t = sum([l > size for l in decode_lengths])\n",
    "            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],\n",
    "                                                                h[:batch_size_t])\n",
    "            # LSTM gate\n",
    "            gate = self.sigmoid(self.f_beta(h[:batch_size_t]))  \n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "            h, c = self.decode_step(\n",
    "                torch.cat([embeddings[:batch_size_t, size, :], attention_weighted_encoding], dim=1),\n",
    "                (h[:batch_size_t], c[:batch_size_t]))\n",
    "            preds = self.fc(self.dropout(h)) \n",
    "            predictions[:batch_size_t, size, :] = preds\n",
    "            alphas[:batch_size_t, size, :] = alpha\n",
    "\n",
    "        return predictions, encoded_captions, decode_lengths, alphas, sort_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model parameters\n",
    "# emb_dim = 512  # dimension of word embeddings\n",
    "# attention_dim = 512  # dimension of attention linear layers\n",
    "# decoder_dim = 512  # dimension of decoder RNN\n",
    "# dropout = 0.3\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "emb_dim = 512  # dimension of word embeddings\n",
    "attention_dim = 1024  # dimension of attention linear layers\n",
    "decoder_dim = 1024  # dimension of decoder RNN\n",
    "dropout = 0.3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderWithAttention(attention_dim=attention_dim,\n",
    "                                       embed_dim=emb_dim,\n",
    "                                       decoder_dim=decoder_dim,\n",
    "                                       vocab_size=len(word2idx),\n",
    "                                       dropout=dropout)\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "encoder=Encoder(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cap_val(captions,word2idx,max_len):\n",
    "    \n",
    "    encoded_captions=[]\n",
    "    for cap in captions:\n",
    "        encoded=[]\n",
    "        tokens=nltk.tokenize.word_tokenize(cap.lower())\n",
    "        encoded.append(word2idx['<start>'])\n",
    "        for token in tokens:\n",
    "            if token in word2idx.keys():\n",
    "                encoded.append(word2idx[token])\n",
    "            else:\n",
    "                encoded.append(word2idx['<unknown>'])\n",
    "        encoded.append(word2idx['<end>'])\n",
    "        encoded.extend([word2idx['<pad>']]*(max_len-len(tokens)))\n",
    "        encoded_captions.append(encoded)\n",
    "    return encoded_captions\n",
    "\n",
    "def encode_captions(annon_file,word2idx,max_len):\n",
    "    coco=COCO(annon_file)\n",
    "    ordered = OrderedDict(sorted(coco.anns.items(), key=lambda i: i[1]['image_id']))\n",
    "    keys=list(ordered.keys())\n",
    "    encoded_captions=[]\n",
    "    lengths=[]\n",
    "    image_ids=[]\n",
    "    \n",
    "    index=0\n",
    "    for key in keys:\n",
    "        encoded=[]\n",
    "        caption=ordered[key]['caption']\n",
    "        image_id=ordered[key]['image_id']\n",
    "        tokens=nltk.tokenize.word_tokenize(caption.lower())\n",
    "        encoded.append(word2idx['<start>'])\n",
    "        for token in tokens:\n",
    "            if token in word2idx.keys():\n",
    "                encoded.append(word2idx[token])\n",
    "            else:\n",
    "                encoded.append(word2idx['<unknown>'])\n",
    "        lengths.append(len(tokens)+2)\n",
    "        encoded.append(word2idx['<end>'])\n",
    "        encoded.extend([word2idx['<pad>']]*(max_len-len(tokens)))\n",
    "        encoded_captions.append(encoded)        \n",
    "        image_ids.append(image_id)\n",
    "\n",
    "    return encoded_captions,lengths,image_ids\n",
    "\n",
    "def decode_caption(idx2word,cap_list):\n",
    "    \n",
    "    decoded_caption=[]\n",
    "    for caption in cap_list:\n",
    "        decoded=[]\n",
    "        for token in caption:\n",
    "            if token==3:\n",
    "                break\n",
    "            decoded.append(idx2word[token])\n",
    "            \n",
    "        decoded_caption.append(decoded)\n",
    "    return decoded_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self,data_list,encoded_captions,lengths,image_ids,val=False):\n",
    "        \n",
    "        self.data=data_list\n",
    "        self.encoded_captions=encoded_captions\n",
    "        self.cap_lens=lengths\n",
    "        self.image_ids=image_ids\n",
    "        self.val=val\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        caption=self.encoded_captions[index]\n",
    "        image_id=self.image_ids[index]\n",
    "        length=self.cap_lens[index]\n",
    "        \n",
    "        idx=self.data.ids.index(image_id)\n",
    "        image,captions=self.data[idx]\n",
    "        \n",
    "        caption=torch.tensor(caption)\n",
    "        length=torch.tensor(length)\n",
    "        \n",
    "        if(self.val):\n",
    "#             print (captions)\n",
    "            captions=captions[:4]\n",
    "            all_caps=encode_cap_val(captions,word2idx,100)\n",
    "            all_caps=torch.LongTensor(all_caps)\n",
    "            return image,caption,length,all_caps \n",
    "        else:\n",
    "            return image,caption,length\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.30s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_transform=transforms.Compose([\n",
    "                                transforms.Resize((255,255)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                     std=[0.229, 0.224, 0.225])                               \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "val_list=dset.CocoCaptions(root = '/home/valkyrie/data/2014/val2014/',\n",
    "                        annFile = '/home/valkyrie/data/2014/annotations/captions_val2014.json',\n",
    "                        transform=train_transform)\n",
    "\n",
    "# Val Captions\n",
    "encoded_captions_val,lengths_val,image_ids_val=encode_captions(anon_file_val,word2idx,max_len=100)\n",
    "val_set=CaptionDataset(val_list,encoded_captions_val,lengths_val,image_ids_val,val=True)\n",
    "val_loader=torch.utils.data.DataLoader(val_set,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (base_model): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (_fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Res1\n",
    "# decoder_weights='./checkpoints/decoder_epoch_1_best.pth'\n",
    "# encoder_weights='./checkpoints/encoder_epoch_1_best.pth'\n",
    "\n",
    "decoder_weights='./checkpoints/decoder_epoch_3_best_b3.pth'\n",
    "encoder_weights='./checkpoints/encoder_epoch_3_best_b3.pth'\n",
    "\n",
    "\n",
    "\n",
    "decoder.load_state_dict(torch.load(decoder_weights))\n",
    "encoder.load_state_dict(torch.load(encoder_weights))\n",
    "\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder=decoder.to(device)\n",
    "\n",
    "decoder.eval()\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 5:  26%|       | 52612/202654 [1:10:15<3:20:22, 12.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f902b1353c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Which sequences are incomplete (didn't reach <end>)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         incomplete_inds = [ind for ind, next_word in enumerate(next_word_inds) if\n\u001b[0m\u001b[1;32m     81\u001b[0m                            next_word != word_map['<end>']]\n\u001b[1;32m     82\u001b[0m         \u001b[0mcomplete_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word_inds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincomplete_inds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-f902b1353c10>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Which sequences are incomplete (didn't reach <end>)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         incomplete_inds = [ind for ind, next_word in enumerate(next_word_inds) if\n\u001b[0;32m---> 81\u001b[0;31m                            next_word != word_map['<end>']]\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mcomplete_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word_inds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincomplete_inds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "beam_size=5\n",
    "references = list()\n",
    "hypotheses = list()\n",
    "\n",
    "word_map=word2idx\n",
    "rev_word_map=idx2word\n",
    "vocab_size = len(word_map)\n",
    "\n",
    "# For each image\n",
    "for i, (image, caps, caplens, allcaps) in enumerate(\n",
    "        tqdm(val_loader, desc=\"Beam Size: \" + str(beam_size))):\n",
    "\n",
    "    k = beam_size\n",
    "\n",
    "    # Move to GPU device, if available\n",
    "    image = image.to(device)  \n",
    "\n",
    "    # Encode\n",
    "    encoder_out = encoder(image)  \n",
    "    enc_image_size = encoder_out.size(1)\n",
    "    encoder_dim = encoder_out.size(3)\n",
    "\n",
    "    # Flatten encoding\n",
    "    encoder_out = encoder_out.view(1, -1, encoder_dim)  # (1, num_pixels, encoder_dim)\n",
    "    num_pixels = encoder_out.size(1)\n",
    "\n",
    "#     print (num_pixels)\n",
    "    encoder_out = encoder_out.expand(k, num_pixels, encoder_dim)  # (k, num_pixels, encoder_dim)\n",
    "\n",
    "    k_prev_words = torch.LongTensor([[word_map['<start>']]] * k).to(device)  # (k, 1)\n",
    "\n",
    "    seqs = k_prev_words  # (k, 1)\n",
    "\n",
    "    top_k_scores = torch.zeros(k, 1).to(device)  # (k, 1)\n",
    "\n",
    "    complete_seqs = list()\n",
    "    complete_seqs_scores = list()\n",
    "\n",
    "    # Start decoding\n",
    "    step = 1\n",
    "    h, c = decoder.init_hidden_state(encoder_out)\n",
    "\n",
    "    # s is a number less than or equal to k, because sequences are removed from this process once they hit <end>\n",
    "    while True:\n",
    "\n",
    "        embeddings = decoder.embedding(k_prev_words).squeeze(1)\n",
    "        awe, _ = decoder.attention(encoder_out, h) \n",
    "        gate = decoder.sigmoid(decoder.f_beta(h))  \n",
    "        awe = gate * awe\n",
    "\n",
    "        h, c = decoder.decode_step(torch.cat([embeddings, awe], dim=1), (h, c))\n",
    "\n",
    "        scores = decoder.fc(h)\n",
    "        scores = F.log_softmax(scores, dim=1)\n",
    "\n",
    "        # Add\n",
    "        scores = top_k_scores.expand_as(scores) + scores  # (s, vocab_size)\n",
    "\n",
    "        if step == 1:\n",
    "            top_k_scores, top_k_words = scores[0].topk(k, 0, True, True)  # (s)\n",
    "        else:\n",
    "            # Unroll and find top scores, and their unrolled indices\n",
    "            top_k_scores, top_k_words = scores.view(-1).topk(k, 0, True, True)  # (s)\n",
    "\n",
    "        prev_word_inds = top_k_words / vocab_size  # (s)\n",
    "        next_word_inds = top_k_words % vocab_size  # (s)\n",
    "\n",
    "        # Add new words to sequences\n",
    "        seqs = torch.cat([seqs[prev_word_inds], next_word_inds.unsqueeze(1)], dim=1)  # (s, step+1)\n",
    "\n",
    "        incomplete_inds = [ind for ind, next_word in enumerate(next_word_inds) if\n",
    "                           next_word != word_map['<end>']]\n",
    "        complete_inds = list(set(range(len(next_word_inds))) - set(incomplete_inds))\n",
    "\n",
    "        if len(complete_inds) > 0:\n",
    "            complete_seqs.extend(seqs[complete_inds].tolist())\n",
    "            complete_seqs_scores.extend(top_k_scores[complete_inds])\n",
    "        k -= len(complete_inds)  # reduce beam length accordingly\n",
    "\n",
    "        # Proceed with incomplete sequences\n",
    "        if k == 0:\n",
    "            break\n",
    "        seqs = seqs[incomplete_inds]\n",
    "        h = h[prev_word_inds[incomplete_inds]]\n",
    "        c = c[prev_word_inds[incomplete_inds]]\n",
    "        encoder_out = encoder_out[prev_word_inds[incomplete_inds]]\n",
    "        top_k_scores = top_k_scores[incomplete_inds].unsqueeze(1)\n",
    "        k_prev_words = next_word_inds[incomplete_inds].unsqueeze(1)\n",
    "\n",
    "        if step > 50:\n",
    "            break\n",
    "        step += 1\n",
    "\n",
    "    i = complete_seqs_scores.index(max(complete_seqs_scores))\n",
    "    seq = complete_seqs[i]\n",
    "\n",
    "    # References\n",
    "    img_caps = allcaps[0].tolist()\n",
    "    img_captions = list(\n",
    "        map(lambda c: [w for w in c if w not in {word_map['<start>'], word_map['<end>'], word_map['<pad>']}],\n",
    "            img_caps))  # remove <start> and pads\n",
    "    references.append(img_captions)\n",
    "\n",
    "    # Hypotheses\n",
    "    hypotheses.append([w for w in seq if w not in {word_map['<start>'], word_map['<end>'], word_map['<pad>']}])\n",
    "\n",
    "    assert len(references) == len(hypotheses)\n",
    "\n",
    "# Calculate BLEU-4 scores\n",
    "bleu4 = corpus_bleu(references, hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2462556677667717\n"
     ]
    }
   ],
   "source": [
    "result = {'bleu4': bleu4}\n",
    "f = open( './bleu4.txt', 'w' )\n",
    "f.write( 'bleu4 = ' + repr(result) + '\\n' )\n",
    "f.close()\n",
    "print (bleu4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (1.0/1.0, )\n",
    "bleu1=corpus_bleu(references, hypotheses, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=(1.0/2.0, 1.0/2.0,)\n",
    "bleu2=corpus_bleu(references, hypotheses, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=(1.0/3.0, 1.0/3.0, 1.0/3.0,)\n",
    "bleu3=corpus_bleu(references, hypotheses, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'bleu4': bleu4,'bleu3': bleu3,'bleu2': bleu2,'bleu1': bleu1}\n",
    "f = open( './results_withoutfine.txt', 'w' )\n",
    "f.write( 'results' + repr(result) + '\\n' )\n",
    "f.close()\n",
    "# print (bleu4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
